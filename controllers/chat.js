import express from "express";
import axios from "axios";
import dotenv from "dotenv";
import { openai } from "../index.js";
export const newChat = async (req, res) => {
  try {
    const { idea } = req.body;
    const response = await openai.createChatCompletion({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "You are a helpful assistant." }, // this represents the bot and what role they will assume
        { role: "user", content: idea }, // the message that the user sends
      ],
    });

    console.log("üöÄ ~ response:", response.data.choices[0].message.content);

    const { data } = response;

    // res.status(200).json({ message });
  } catch (error) {
    // console.error("error", error);
    res.status(500).json({ error: error.message });
  }
};

// data: {
//   id: 'chatcmpl-6t64qPVL9XjgrPRcoMdwqSQJxTisE',
//   object: 'chat.completion',
//   created: 1678589420,
//   model: 'gpt-3.5-turbo-0301',
//   usage: { prompt_tokens: 19, completion_tokens: 28, total_tokens: 47 },
//   choices: [
//    {
//       message: {
//         role: 'assistant',
//        content: 'Is there anything specific you need assistance with?'
//      },
//      finish_reason: 'stop',
//      index: 0
//    }
//  ]
// }

// Example
// h∆∞·ªõng d·∫´n c√°ch gi·∫£i ph∆∞∆°ng tr√¨nh b·∫≠c 2
// ƒê·ªÉ gi·∫£i ph∆∞∆°ng tr√¨nh b·∫≠c 2: ax¬≤ + bx + c = 0, ta l√†m theo c√°c b∆∞·ªõc sau:

// 1. T√≠nh delta (Œî) = b¬≤ - 4ac
// 2. N·∫øu Œî > 0, ph∆∞∆°ng tr√¨nh c√≥ 2 nghi·ªám ph√¢n bi·ªát: x1 = (-b + ‚àöŒî) / 2a v√† x2 = (-b - ‚àöŒî) / 2a
// 4. N·∫øu Œî < 0, ph∆∞∆°ng tr√¨nh kh√¥ng c√≥ nghi·ªám th·ª±c.

// V√≠ d·ª•:

// Gi·∫£i ph∆∞∆°ng tr√¨nh x¬≤ + 3x - 4 = 0

// 1. T√≠nh delta: Œî = 3¬≤ - 4*1*(-4) = 25
// 2. Œî > 0, c√≥ 2 nghi·ªám ph√¢n bi·ªát: x1 = (-3 + ‚àö25) / 2*1 = 1 v√† x2 = (-3 - ‚àö25) / 2*1 = -4

// V·∫≠y ph∆∞∆°ng tr√¨nh c√≥ 2 nghi·ªám l√† x1 = 1 v√† x2 = -4.
